{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import important libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.poemhunter.com/mary-oliver/poems/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response.status_code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.poemhunter.com/mary-oliver/poems/page-2/\n",
      "Status code: 200\n",
      "I will sleep for 0.499 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-3/\n",
      "Status code: 200\n",
      "I will sleep for 3.272 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-4/\n",
      "Status code: 200\n",
      "I will sleep for 3.584 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-5/\n",
      "Status code: 200\n",
      "I will sleep for 3.815 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-6/\n",
      "Status code: 200\n",
      "I will sleep for 1.861 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-7/\n",
      "Status code: 200\n",
      "I will sleep for 0.671 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-8/\n",
      "Status code: 200\n",
      "I will sleep for 1.884 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-9/\n",
      "Status code: 200\n",
      "I will sleep for 3.261 second/s.\n",
      "https://www.poemhunter.com/mary-oliver/poems/page-10/\n",
      "Status code: 200\n",
      "I will sleep for 2.512 second/s.\n"
     ]
    }
   ],
   "source": [
    "# Get all the pages from poemhunter with Mary Oliver's poems:\n",
    "\n",
    "#URLs:\n",
    "# second page: https://www.poemhunter.com/mary-oliver/poems/page-2/\n",
    "# last page: https://www.poemhunter.com/mary-oliver/poems/page-10/\n",
    "\n",
    "\n",
    "pages = [] #list of all responses\n",
    "\n",
    "#start with the first page, that has a slightly different url:\n",
    "url ='https://www.poemhunter.com/mary-oliver/poems/'\n",
    "print(url)\n",
    "response = requests.get(url)\n",
    "print(\"Status code: \" + str(response.status_code))\n",
    "pages.append(response)\n",
    "\n",
    "\n",
    "#In this for-loop the pages 2-10 are scraped and put into pages:\n",
    "for i in range(2,11):\n",
    "    page= str(i)\n",
    "    url = \"https://www.poemhunter.com/mary-oliver/poems/page-\" + page + \"/\"\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    print(\"Status code: \" + str(response.status_code))\n",
    "    \n",
    "    # store response into \"pages\" list\n",
    "    pages.append(response)\n",
    "    \n",
    "    # respectful nap:\n",
    "    wait_time = randint(1,4000)\n",
    "    print(\"I will sleep for \" + str(wait_time/1000) + \" second/s.\")\n",
    "    sleep(wait_time/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(BeautifulSoup(pages[0].content, \"html.parser\").prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the soup of one page:\n",
    "soup = BeautifulSoup(pages[0].content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"phContent phcText phProfilePoemsContent\">\n",
       "             There is a thing in me that dreamed of trees, \n",
       " <br/>A quiet house, some green and modest acres\n",
       " <br/>A little way from every troubling town, \n",
       " <br/>A little way from factories, schools, laments.<br/>...\n",
       "         </p>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('#profilePoems > div:nth-child(1) > p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "poems = []\n",
    "\n",
    "for i in range(len(pages)):\n",
    "    # parse all pages\n",
    "    parsed = BeautifulSoup(pages[i].content, \"html.parser\")\n",
    "    \n",
    "    # creating the title soup\n",
    "    title_soup = parsed.select('div.phlRow > div > a > span')\n",
    "    \n",
    "    #And append every title to the titles list\n",
    "    for item in title_soup:\n",
    "        titles.append(item.get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span>A Dream Of Trees </span>,\n",
       " <span>A Visitor </span>,\n",
       " <span>Wild Geese </span>,\n",
       " <span>The Journey </span>,\n",
       " <span>When Death Comes </span>,\n",
       " <span>After Arguing Against The Contention That Art Must Come From Discontent </span>,\n",
       " <span>Mindful </span>,\n",
       " <span>August </span>,\n",
       " <span>A Meeting </span>,\n",
       " <span>At Blackwater Pond </span>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_soup = soup.select('div.phlRow > div > a > span')\n",
    "title_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titl=[]\n",
    "for i in title_soup:\n",
    "    t= i.get_text()\n",
    "    titl.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Dream Of Trees ', 'A Visitor ', 'Wild Geese ', 'The Journey ', 'When Death Comes ', 'After Arguing Against The Contention That Art Must Come From Discontent ', 'Mindful ', 'August ', 'A Meeting ', 'At Blackwater Pond ']\n"
     ]
    }
   ],
   "source": [
    "print(titl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
